---
title: "Guidelines: appli mapdO"
output: 
  html_document:
    toc: true
---


```{r setup}
library(mapdO)
library(dplyr)
```

Démo [ici](https://analytics.huma-num.fr/Lise.Vaudor/mapdO_demo1/)

Repo github [ici](https://github.com/lvaudor/mapdO/)

# Etat actuel de l'appli

## Structure

Pour l'instant, deux modules:

- un module **profils**
- un module **modèles régionaux**

Les deux jeux de données sont pour l'instant différents pour les deux modules:

il faudra, in fine, homogénéiser ça quand les jeux de données "définitifs" seront disponibles. 
Pour le module {modèles régionaux}, j'utilise le jeu de données d'Elise sur RMC.
Cela me permet de tester différents types de combinaisons de variables x-y. 
Par contre le référentiel n'est pas le même que celui utilisé pour le module {profils}. Cela devrait être réglé lorsqu'on utilisera des données récentes et propres pour ce module.

Quelques points à discuter pour améliorer la **lisibilité de l'appli**: 

- quels noms donner aux **couches d'information géographiques**
- quels noms donner aux **modules**?
- comment **légender** les différents widgets
- L'appli sera-t-elle en **français** ou en **anglais**?


## Interactivité

## Layout

Pour l'instant j'ai appelé l'appli **mapdO** et j'ai fait un faux logo vite fait pour la démo.

J'ai choisi un menu type "tabs" pour les différents modules mais on peut sans difficulté tester des types de menus différents.

La **disposition côte à côte** (sur la largeur) de la carte et du graphique permet à mon avis de tirer parti au maximum de l'écran.

## Déploiement

Pour l'instant l'appli fonctionne sur mon **compte Shiny Server huma-num**, et ne repose que sur R/shiny 
(pas d'intégration des données sur QGIS server, pas de dockerisation pour l'instant).

# Etat actuel des données

## Données régionales

- Référentiel de JeuDeDonneesEBFVar à jeter car pb identifiant => utilisé actuellement pour datsp (envoi par Christophe en ../09/20 )
- métriques du Var de JeudeDonneesEBFVar <=> Axe 1 (??) (envoi par Christophe en ../09/20 )
- Référentiel RMC (envoi par Samuel le 21/10/20) => à intégrer comme carte régionale pour module "profils"
- métriques de l'Isère (envoi par Samuel le 21/10/20)
- métriques de l'Isère (AX0005) de l'Arc (AX0012) le Drac (AX0009) (envoi par Christophe le 21/10/20)

```{r}
#fs::dir_tree("../data-raw/extdata/IsereEtAffluents/AX0005/METRICS")
```


# Package

## Contenu du package mapdO

```{r, echo=FALSE}
listFunctions <- function(function.name, all_functions){
  function_code <- deparse(get(function.name)) %>% paste(collapse=" ")
  tib_result=tibble::tibble(called_functions=all_functions) %>% 
    mutate(detect=paste0(called_functions,"\\s*\\(")) %>% 
    group_by(detect) %>% 
    mutate(detected=purrr::map_lgl(.x=detect,
                                   ~stringr::str_detect(function_code,.x))) %>% 
    filter(detected) %>%
    ungroup() %>% 
    select(called_functions) 
  return(tib_result)
}
```


```{r}
funs_mapdO=tibble(functions=ls("package:mapdO")) %>% 
  mutate(app_utils=stringr::str_detect(functions,"mod_|app")) %>%
  mutate(app_ui=stringr::str_detect(functions,"_ui")) %>% 
  filter(app_ui==FALSE) %>% 
  group_by(functions,app_utils)  %>%
  mutate(calls_functions=purrr::map(functions,listFunctions,all_functions=.$functions)) %>% 
  tidyr::unnest(cols=calls_functions)

nodes=funs_mapdO$functions %>% unique() %>% paste(collapse=";")
edges=funs_mapdO %>% 
  dplyr::mutate(edges=purrr::map2_chr(.x=functions,
                              .y=called_functions,
                              ~ paste(.x,"->",.y))) %>% 
  dplyr::pull(edges) %>% 
  paste(collapse=" ")

DiagrammeR::grViz(paste("
digraph boxes_and_circles {

  # a 'graph' statement
  graph [overlap = true, fontsize = 10]

  # several 'node' statements
  node [shape = box,
        fontname = Helvetica]",
  nodes,
  edges,
  "}")
)
```

Tables de correspondance

```{r}
table_metrics

table_regmod
```


# To-do list

## A faire prochainement

- Changer les noms des datasets pour qqch de plus générique (exple datRMC => data_regional)
- Organiser les scripts de préparation des données (pour l'instant tout est rassemblé dans data-raw/dataset.R)
- Brush plot vers carte => brush carte vers plot
- Profils => ajuster graphiques des landcovers: side, type
- Faire des widgets simplifiés pour choix des métriques

## A refaire régulièrement

- **Nettoyage** (nettoyage des prints, suppression des éléments tests)
- **Modularisation**
- **Documentation** (fonctions, vignette)
- Commit + Push sur **repo github**

# Notes pour dev

## Utilisation de golem pour la production de l'appli

Bouquin de ThinkR sur golem [ici](https://engineering-shiny.org/)

golem aide à écrire une appli "production-ready" et repose sur divers principes

- **une appli=un package**. On retrouve de ce fait un certain nombre de principes liés à la construction d'un package (documentation, fourniture de données comme faisant partie du package, écriture de vignette, tests, etc.) => package usethis notamment.

- **une appli= un assortiment de modules** qui fonctionnent indépendamment les uns des autres. De ce fait, chaque module correspond à un "namespace" qui lui est propre. Voir article de C. Girard "La communication entre modles et ses caprices" [ici](https://rtask.thinkr.fr/fr/la-communication-entre-modules-et-ses-caprices/) si besoin de faire passer des éléments d'un module à l'autre. 

## Fonctionnement sur compte Shiny Server Huma-num

Attention, fonctionnement de Shiny Server avec la version de R 3.5 pour le moment (alors que Shiny Desktop a par défaut la version 3.6).

Par ailleurs, les packages chargés par Shiny Server peuvent être ceux installés par Huma-Num plutôt que les packages "User" => problèmes éventuels avec les versions des packages, par exemple package `vctrs`. 

Ajout des lignes de commande suivantes dans app.R:

```{r}
mylibraries=c(.libPaths(),
              "../../../R/x86_64-pc-linux-gnu-library/3.5")
library(vctrs,lib.loc=mylibraries)
library(rlang,lib.loc=mylibraries)
```

# Remarques

Forcer le render de guidelines:

```{r,eval=FALSE}
rmarkdown::render("vignettes/guidelines.Rmd")
```
# Message / Données mapdO

Données EBF Grands Axes
Ce n'est pas encore parfait, mais c'est ce que j'ai pu faire rapidement ;
je n'ai pas réussi à rassembler tous les profils en travers dans un seul fichier et il manque les variables calculées pour le tracé en plan.
Je vous enverrai un update quand j'aurais réglé mes derniers problèmes de cuisine.

L'archive contient :

1. un docx avec les tableaux des métriques

2. un dossier 'Référentiel hydro' avec le référentiel hydrographique dérivé de la BD Topo (14 octobre 2020) constitué des cours d'eau d'une longueur > 10 km ayant un identifiant BD Carthage ;
deux versions : FINAL = réseau de tronçons BDT correctement connectés les uns aux autres, AGG = tronçons agrégés par axe hydrographique.
Identifiant numérique des axes hydrographiques = champ AXIS.
Chaque axe hydrographique a aussi un identifiant BD Carthage CdEntiteHydr

3. un dossier 'Hypsomètres' avec les hypsomètres par zone hydro et classe d'occupation du sol

4. un dossier 'Grands Axes' avec les données EBF pour les 19 cours d'eau les plus longs du bassin du Rhône, avec :

+ REF_HYDRO => un extrait du référentiel hydrographique avec les grands axes + les axes de référence (REFAXIS.shp) qui correspondent ici à l'axe médian du FDV
+ les cartes produites avec la FCT : occupation du sol, hauteurs relatives, continuité latérale avec un projet QGis pour les visualiser (c'est celui que j'ai déployé dans QGis Server si vous voulez tout savoir)
+ pour chaque axe un dossier AXES/AXnnnn avec
- MEASURE/SWATHS_REFAXIS.shp => les polygones de DGOs = swaths de 200 m de long
- METRICS/PLANFORM.nc => variables du tracé en plan qui ne correspondent pas à des DGO mais qui sont repérés dans le même système de coordonnée (axis, measure)
- METRICS/LONG_PROFILE.nc => métriques par DGO = profil longitudinal
- METRICS/SWATDonnées EBF Grands Axes
Ce n'est pas encore parfait, mais c'est ce que j'ai pu faire rapidement ;
je n'ai pas réussi à rassembler tous les profils en travers dans un seul fichier et il manque les variables calculées pour le tracé en plan.
Je vous enverrai un update quand j'aurais réglé mes derniers problèmes de cuisine.

L'archive contient :

1. un docx avec les tableaux des métriques

2. un dossier 'Référentiel hydro' avec le référentiel hydrographique dérivé de la BD Topo (14 octobre 2020) constitué des cours d'eau d'une longueur > 10 km ayant un identifiant BD Carthage ;
deux versions : FINAL = réseau de tronçons BDT correctement connectés les uns aux autres, AGG = tronçons agrégés par axe hydrographique.
Identifiant numérique des axes hydrographiques = champ AXIS.
Chaque axe hydrographique a aussi un identifiant BD Carthage CdEntiteHydr

3. un dossier 'Hypsomètres' avec les hypsomètres par zone hydro et classe d'occupation du sol

4. un dossier 'Grands Axes' avec les données EBF pour les 19 cours d'eau les plus longs du bassin du Rhône, avec :

+ REF_HYDRO => un extrait du référentiel hydrographique avec les grands axes + les axes de référence (REFAXIS.shp) qui correspondent ici à l'axe médian du FDV
+ les cartes produites avec la FCT : occupation du sol, hauteurs relatives, continuité latérale avec un projet QGis pour les visualiser (c'est celui que j'ai déployé dans QGis Server si vous voulez tout savoir)
+ pour chaque axe un dossier AXES/AXnnnn avec
- MEASURE/SWATHS_REFAXIS.shp => les polygones de DGOs = swaths de 200 m de long
- METRICS/PLANFORM.nc => variables du tracé en plan qui ne correspondent pas à des DGO mais qui sont repérés dans le même système de coordonnée (axis, measure)
- METRICS/LONG_PROFILE.nc => métriques par DGO = profil longitudinal
- METRICS/SWATHS_*.nc => profils en traversHS_*.nc => profils en travers
